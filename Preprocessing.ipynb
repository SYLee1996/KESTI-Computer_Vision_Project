{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "import datatable as dt\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from utils import path_list, coordinate_matching, calc_chan_mean, calc_grid_mean, dummy_and_add_feature, feature_encoding\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "folder_path = '/data/COMPUTER_VISION/_wizai/'\n",
    "scaler_path = '/data/COMPUTER_VISION/AMSU_PREP/Data/TETE_min-max_scaler.pickle'\n",
    "\n",
    "select_list = [4,5,6,7,8,9,10,11,12,13]\n",
    "\n",
    "SET_range= {\n",
    "        \"TRAIN\": [\"202106\", \"20210710\"],\n",
    "        \"VALID\": [\"20210711\", \"20210720\"],\n",
    "        \"TEST\": [\"20210721\", \"20210731\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9a05ee4e0006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# in4bc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0min4bc_open_netcdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min4bc_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0min4bc_xrdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min4bc_open_netcdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0min4bc_xrdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min4bc_xrdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0min4bc_xrdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'npredictors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nchans'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sat_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scanpos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lon'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chqcflag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bias_pred'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'obsTB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'innov'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0min4bc_xrdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'nchans'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'nchan'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   5742\u001b[0m             \u001b[0mnew_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5743\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5744\u001b[0;31m             \u001b[0mnew_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5746\u001b[0m         \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5931\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5932\u001b[0m         \"\"\"\n\u001b[0;32m-> 5933\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5934\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5935\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.exists('Data') is False:\n",
    "    os.makedirs('Data')\n",
    "    \n",
    "for save_path in ['/data/COMPUTER_VISION/AMSU_PREP/Data/Normal', '/data/COMPUTER_VISION/AMSU_PREP/Data/Abnormal']:\n",
    "    if os.path.exists(save_path) is False:\n",
    "            os.makedirs(save_path)\n",
    "            \n",
    "not_scale_col = ['nchan', 'sat_id', 'scanpos', 'lat', 'lon', 'REAL_QC', 'grid', 'chan_lat_mean', 'chan_lon_mean', 'grid_lat_mean', 'grid_lon_mean',\n",
    "                        'sin_hour', 'cos_hour', 'sin_day', 'cos_day', 'sin_month', 'cos_month', 'chqcflag_-999', 'chqcflag_0']\n",
    "scale_col = ['bias_pred', 'obsTB', 'innov', 'chan_bias_pred_mean', 'chan_obsTB_mean', 'chan_innov_mean', 'grid_bias_pred_mean', 'grid_obsTB_mean', 'grid_innov_mean']\n",
    "temp_dict = {key:[np.nan,np.nan] for key in scale_col}\n",
    "\n",
    "if not os.path.exists(scaler_path):\n",
    "    print('scaler')\n",
    "    for MODE in ['TRAIN', 'VALID']:\n",
    "        in4bc_path_list, thinn_path_list = path_list(folder_path, SET_range, MODE)\n",
    "\n",
    "        for in4bc_path, InnQC2_path in tqdm(zip(in4bc_path_list, thinn_path_list), total=len(thinn_path_list)):\n",
    "        \n",
    "            # in4bc\n",
    "            in4bc_open_netcdf = xr.open_dataset(in4bc_path)\n",
    "            in4bc_xrdataset = in4bc_open_netcdf.to_dataframe().reset_index()\n",
    "            in4bc_xrdataset = in4bc_xrdataset[in4bc_xrdataset['npredictors']==0][['nchans', 'sat_id', 'scanpos', 'lat', 'lon', 'chqcflag', 'bias_pred', 'obsTB', 'innov']].reset_index(drop=True)\n",
    "            in4bc_xrdataset.rename(columns={'nchans':'nchan'}, inplace=True)\n",
    "            in4bc_xrdataset = in4bc_xrdataset[in4bc_xrdataset['nchan'].isin(select_list)].reset_index(drop=True)\n",
    "\n",
    "            # pre-thinning\n",
    "            pre_thinning_df = dt.fread(InnQC2_path, encoding = \"utf-8\").to_pandas().iloc[:,1:]\n",
    "            pre_thinning_df = pre_thinning_df[pre_thinning_df['irej'] == 0].reset_index(drop=True)\n",
    "            pre_thinning_df['lat'] = pre_thinning_df['lat'].astype(np.float32)\n",
    "            pre_thinning_df['lon'] = pre_thinning_df['lon'].astype(np.float32)\n",
    "            pre_thinning_df.drop(['irej', 'isat', 'bpos', 'QCflag', 'sfctype', 'obstdif', \n",
    "                                'ob(01)', 'ob(02)', 'ob(03)', 'ob(04)', 'ob(05)', 'ob(06)', 'ob(07)', 'ob(08)', 'ob(09)','ob(10)', 'ob(11)', 'ob(12)','ob(13)', 'ob(14)', 'ob(15)',\n",
    "                                'bk(01)', 'bk(02)', 'bk(03)', 'bk(04)', 'bk(05)', 'bk(06)', 'bk(07)', 'bk(08)', 'bk(09)','bk(10)', 'bk(11)', 'bk(12)','bk(13)', 'bk(14)', 'bk(15)',\n",
    "                                'cob(01)', 'cob(02)', 'cob(03)', 'cob(04)', 'cob(05)', 'cob(06)', 'cob(07)', 'cob(08)', 'cob(09)','cob(10)', 'cob(11)', 'cob(12)','cob(13)', 'cob(14)', 'cob(15)',\n",
    "                                'ck(01)', 'ck(02)', 'ck(03)', 'ck(04)', 'ck(15)'], axis=1, inplace=True)\n",
    "            \n",
    "            in4bc_df_labeling = coordinate_matching(in4bc_xrdataset, pre_thinning_df, select_list)\n",
    "            in4bc_df_labeling_class = calc_chan_mean(in4bc_df_labeling, select_list)\n",
    "            in4bc_df_grid = calc_grid_mean(in4bc_df_labeling_class, select_list)   \n",
    "            in4bc_df_grid[['sin_hour', 'cos_hour', 'sin_day', 'cos_day', 'sin_month', 'cos_month']] = dummy_and_add_feature(in4bc_path)\n",
    "            in4bc_df_encoding = feature_encoding(in4bc_df_grid)\n",
    "            \n",
    "            del in4bc_open_netcdf; del in4bc_xrdataset; del pre_thinning_df; del in4bc_df_labeling; del in4bc_df_labeling_class; del in4bc_df_grid;\n",
    "                    \n",
    "            # stn마다 변수별 최대, 최소값 구하기\n",
    "            max_arr = in4bc_df_encoding[scale_col].max().values\n",
    "            min_arr = in4bc_df_encoding[scale_col].min().values\n",
    "                \n",
    "            # 사전에 변수별 최대, 최소값 저장\n",
    "            min_max_dict = {scale_col[i]:[min_arr[i], max_arr[i]] for i in range(len(scale_col))}\n",
    "            \n",
    "            for key in temp_dict.keys():\n",
    "                temp_dict[key][0]=min(min_max_dict[key][0], temp_dict[key][0])\n",
    "                temp_dict[key][1]=max(min_max_dict[key][1], temp_dict[key][1])\n",
    "                \n",
    "    with open(scaler_path, 'wb') as fw:\n",
    "        pickle.dump(temp_dict, fw)\n",
    "    print(\"scaler is saved at {}\".format(scaler_path))\n",
    "                \n",
    "else:\n",
    "    for MODE in ['TRAIN', 'VALID', 'TEST']:\n",
    "        in4bc_path_list, thinn_path_list = path_list(folder_path, SET_range, MODE)\n",
    "\n",
    "        for in4bc_path, InnQC2_path in tqdm(zip(in4bc_path_list, thinn_path_list), total=len(thinn_path_list)):\n",
    "        \n",
    "            # in4bc\n",
    "            in4bc_open_netcdf = xr.open_dataset(in4bc_path)\n",
    "            in4bc_xrdataset = in4bc_open_netcdf.to_dataframe().reset_index()\n",
    "            in4bc_xrdataset = in4bc_xrdataset[in4bc_xrdataset['npredictors']==0][['nchans', 'sat_id', 'scanpos', 'lat', 'lon', 'chqcflag', 'bias_pred', 'obsTB', 'innov']].reset_index(drop=True)\n",
    "            in4bc_xrdataset.rename(columns={'nchans':'nchan'}, inplace=True)\n",
    "            in4bc_xrdataset = in4bc_xrdataset[in4bc_xrdataset['nchan'].isin(select_list)].reset_index(drop=True)\n",
    "\n",
    "            # pre-thinning\n",
    "            pre_thinning_df = dt.fread(InnQC2_path, encoding = \"utf-8\").to_pandas().iloc[:,1:]\n",
    "            pre_thinning_df = pre_thinning_df[pre_thinning_df['irej'] == 0].reset_index(drop=True)\n",
    "            pre_thinning_df['lat'] = pre_thinning_df['lat'].astype(np.float32)\n",
    "            pre_thinning_df['lon'] = pre_thinning_df['lon'].astype(np.float32)\n",
    "            pre_thinning_df.drop(['irej', 'isat', 'bpos', 'QCflag', 'sfctype', 'obstdif', \n",
    "                                'ob(01)', 'ob(02)', 'ob(03)', 'ob(04)', 'ob(05)', 'ob(06)', 'ob(07)', 'ob(08)', 'ob(09)','ob(10)', 'ob(11)', 'ob(12)','ob(13)', 'ob(14)', 'ob(15)',\n",
    "                                'bk(01)', 'bk(02)', 'bk(03)', 'bk(04)', 'bk(05)', 'bk(06)', 'bk(07)', 'bk(08)', 'bk(09)','bk(10)', 'bk(11)', 'bk(12)','bk(13)', 'bk(14)', 'bk(15)',\n",
    "                                'cob(01)', 'cob(02)', 'cob(03)', 'cob(04)', 'cob(05)', 'cob(06)', 'cob(07)', 'cob(08)', 'cob(09)','cob(10)', 'cob(11)', 'cob(12)','cob(13)', 'cob(14)', 'cob(15)',\n",
    "                                'ck(01)', 'ck(02)', 'ck(03)', 'ck(04)', 'ck(15)'], axis=1, inplace=True)\n",
    "            \n",
    "            in4bc_df_labeling = coordinate_matching(in4bc_xrdataset, pre_thinning_df, select_list)\n",
    "            in4bc_df_labeling_class = calc_chan_mean(in4bc_df_labeling, select_list)\n",
    "            in4bc_df_grid = calc_grid_mean(in4bc_df_labeling_class, select_list)   \n",
    "            in4bc_df_grid[['sin_hour', 'cos_hour', 'sin_day', 'cos_day', 'sin_month', 'cos_month']] = dummy_and_add_feature(in4bc_path)\n",
    "            in4bc_df_encoding = feature_encoding(in4bc_df_grid)\n",
    "            \n",
    "            del in4bc_open_netcdf; del in4bc_xrdataset; del pre_thinning_df; del in4bc_df_labeling; del in4bc_df_labeling_class; del in4bc_df_grid;\n",
    "            \n",
    "            with open(scaler_path, 'rb') as fr:\n",
    "                min_max_dict = pickle.load(fr)\n",
    "        \n",
    "            # min-max scaling\n",
    "            for col, (col_min, col_max) in min_max_dict.items():\n",
    "                in4bc_df_encoding[col] = in4bc_df_encoding[col] - col_min\n",
    "                in4bc_df_encoding[col] = in4bc_df_encoding[col] / (col_max-col_min)\n",
    "\n",
    "            in4bc_df_encoding['lat'] = in4bc_df_encoding['lat']/90\n",
    "            in4bc_df_encoding['lon'] = in4bc_df_encoding['lon']/360\n",
    "            in4bc_df_encoding['chan_lat_mean'] = in4bc_df_encoding['chan_lat_mean']/90\n",
    "            in4bc_df_encoding['chan_lon_mean'] = in4bc_df_encoding['chan_lon_mean']/360\n",
    "            in4bc_df_encoding['grid_lat_mean'] = in4bc_df_encoding['grid_lat_mean']/90\n",
    "            in4bc_df_encoding['grid_lon_mean'] = in4bc_df_encoding['grid_lon_mean']/360\n",
    "            \n",
    "            normal_data   = in4bc_df_encoding[in4bc_df_encoding['REAL_QC'] == 0.0].fillna(1).reset_index(drop=True)\n",
    "            abnormal_data = in4bc_df_encoding[in4bc_df_encoding['REAL_QC'] == 7.0].fillna(1).reset_index(drop=True)\n",
    "            \n",
    "            normal_data.drop(['REAL_QC'], axis=1, inplace=True)\n",
    "            abnormal_data.drop(['REAL_QC'], axis=1, inplace=True)\n",
    "            \n",
    "            torch.save(normal_data, \"/data/COMPUTER_VISION/AMSU_PREP/Data/Normal/{}_{}_Normal_data.pkl\".format(in4bc_path.split(\"_\")[-1].split(\".\")[0], MODE), pickle_module=pickle)\n",
    "            torch.save(abnormal_data, \"/data/COMPUTER_VISION/AMSU_PREP/Data/Abnormal/{}_{}_Abnormal_data.pkl\".format(in4bc_path.split(\"_\")[-1].split(\".\")[0], MODE), pickle_module=pickle)\n",
    "            del in4bc_df_encoding; del normal_data; del abnormal_data;\n",
    "            \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
